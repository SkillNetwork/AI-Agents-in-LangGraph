{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Lesson 4: Persistence and Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_KNBFCIwIIuLYeeK2np8yTi4M', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 151, 'total_tokens': 173, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_057232b607', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-00bfe81f-8dc7-4685-b5ed-114da64aaf1f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_KNBFCIwIIuLYeeK2np8yTi4M'}])]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_KNBFCIwIIuLYeeK2np8yTi4M'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1727403273, \\'localtime\\': \\'2024-09-26 19:14\\'}, \\'current\\': {\\'last_updated_epoch\\': 1727402400, \\'last_updated\\': \\'2024-09-26 19:00\\', \\'temp_c\\': 20.6, \\'temp_f\\': 69.1, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 6.5, \\'wind_kph\\': 10.4, \\'wind_degree\\': 259, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1012.0, \\'pressure_in\\': 29.87, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 68, \\'cloud\\': 25, \\'feelslike_c\\': 20.6, \\'feelslike_f\\': 69.1, \\'windchill_c\\': 14.9, \\'windchill_f\\': 58.8, \\'heatindex_c\\': 15.1, \\'heatindex_f\\': 59.2, \\'dewpoint_c\\': 14.1, \\'dewpoint_f\\': 57.3, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 1.0, \\'gust_mph\\': 11.5, \\'gust_kph\\': 18.6}}\"}, {\\'url\\': \\'https://www.timeanddate.com/weather/usa/san-francisco/hourly\\', \\'content\\': \\'Hour-by-Hour Forecast for San Francisco, California, USA. Currently: 60 °F. Partly sunny. (Weather station: San Francisco International Airport, USA). See more current weather.\\'}]', name='tavily_search_results_json', tool_call_id='call_KNBFCIwIIuLYeeK2np8yTi4M')]\n",
      "[AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of approximately 20.6°C (69.1°F). Here are some more details:\\n\\n- **Wind**: 6.5 mph (10.4 kph) from the west\\n- **Pressure**: 1012.0 mb\\n- **Humidity**: 68%\\n- **Visibility**: 16 km (9 miles)\\n- **UV Index**: 1\\n\\nWould you like more detailed weather information or a forecast?', response_metadata={'token_usage': {'completion_tokens': 105, 'prompt_tokens': 656, 'total_tokens': 761, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_057232b607', 'finish_reason': 'stop', 'logprobs': None}, id='run-d674bb4d-ba78-4096-84f6-6853ae57d336-0')]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_rEHJ6L2b3dElAjSCE0v0yo1V', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 773, 'total_tokens': 795, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_057232b607', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7216603c-65a0-49b8-a5ba-c513df809566-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_rEHJ6L2b3dElAjSCE0v0yo1V'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_rEHJ6L2b3dElAjSCE0v0yo1V'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1727403109, \\'localtime\\': \\'2024-09-26 19:11\\'}, \\'current\\': {\\'last_updated_epoch\\': 1727402400, \\'last_updated\\': \\'2024-09-26 19:00\\', \\'temp_c\\': 19.4, \\'temp_f\\': 66.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 226, \\'wind_dir\\': \\'SW\\', \\'pressure_mb\\': 1011.0, \\'pressure_in\\': 29.85, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 76, \\'cloud\\': 0, \\'feelslike_c\\': 19.4, \\'feelslike_f\\': 66.9, \\'windchill_c\\': 22.5, \\'windchill_f\\': 72.5, \\'heatindex_c\\': 23.2, \\'heatindex_f\\': 73.8, \\'dewpoint_c\\': 16.6, \\'dewpoint_f\\': 61.8, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 1.0, \\'gust_mph\\': 7.4, \\'gust_kph\\': 12.0}}\"}, {\\'url\\': \\'https://www.easeweather.com/north-america/united-states/california/los-angeles-county/los-angeles/september\\', \\'content\\': \\'September 2024 Weather - Los Angeles Weather in Los Angeles for September 2024 Your guide to Los Angeles weather in September - trends and predictions The forecast for the upcoming days in Los Angeles predicts a temperature of 33.4\\\\xa0°F, which is slightly above the historical average. In general, the average temperature in Los Angeles at the beginning of September is 33.7\\\\xa0°F. Los Angeles in September average weather Temperatures trend during September in Los Angeles Our weather forecast for Los Angeles in September is based on the analysis of historical data rather than real-time forecast models. Los Angeles in September - FAQ\\'}]', name='tavily_search_results_json', tool_call_id='call_rEHJ6L2b3dElAjSCE0v0yo1V')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is clear with a temperature of approximately 19.4°C (66.9°F). Here are some more details:\\n\\n- **Wind**: 5.6 mph (9.0 kph) from the southwest\\n- **Pressure**: 1011.0 mb\\n- **Humidity**: 76%\\n- **Visibility**: 16 km (9 miles)\\n- **UV Index**: 1\\n\\nWould you like more detailed weather information or a forecast?', response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 1372, 'total_tokens': 1476, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_057232b607', 'finish_reason': 'stop', 'logprobs': None}, id='run-a183cfad-77f5-44e8-a908-bf52b8b9de65-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Currently, San Francisco is slightly warmer than Los Angeles. The temperature in San Francisco is approximately 20.6°C (69.1°F), while in Los Angeles, it is around 19.4°C (66.9°F).', response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 1488, 'total_tokens': 1537, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_057232b607', 'finish_reason': 'stop', 'logprobs': None}, id='run-44e86dee-34c0-45e6-88ec-f616fd3a5eda-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Could you please specify the two items or locations you are comparing to determine which one is warmer? This will help me provide a more accurate answer.', response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 149, 'total_tokens': 179, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_057232b607', 'finish_reason': 'stop', 'logprobs': None}, id='run-376e7210-678f-49a4-beaa-2b26675b039a-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59a36-3941-459e-b9d1-ac5a4a1ed3ae",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_E0MTu2nyjPsbV3IX9xduS2gS'}\n",
      "Back to the model!\n",
      "The| current| weather| in| San| Francisco| is| as| follows|:\n",
      "\n",
      "|-| **|Temperature|:**| |20|.|6|°C| (|69|.|1|°F|)\n",
      "|-| **|Condition|:**| Part|ly| cloudy|\n",
      "|-| **|Wind|:**| |6|.|5| mph| (|10|.|4| k|ph|),| coming| from| the| west|\n",
      "|-| **|Humidity|:**| |68|%\n",
      "|-| **|Visibility|:**| |16| km| (|9| miles|)\n",
      "|-| **|Pressure|:**| |101|2| mb| (|29|.|87| in|)\n",
      "|-| **|UV| Index|:**| |1| (|low|)\n",
      "\n",
      "|It| is| currently| evening| in| San| Francisco|,| and| the| conditions| are| quite| pleasant|.\n",
      "\n",
      "|For| more| detailed| and| hourly| updates|,| you| can| check| websites| like| [|Weather|API|](|https|://|www|.weather|api|.com|/)| and| [|Time| and| Date|](|https|://|www|.time|and|date|.com|/weather|/|usa|/s|an|-fr|anc|isco|/hour|ly|).|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
